logs/TEMPO/loar_revin_100_percent_1_prompt_equal_1/ettm2_pmt1_no_pool_TEMPO_3/test_104_24_lr0.001.log
Namespace(model_id='traffic_TEMPO_3_prompt_learn_104_24_100', checkpoints='./lora_revin_6domain_checkpoints_1/', task_name='long_term_forecast', prompt=1, num_nodes=1, seq_len=104, pred_len=24, label_len=18, decay_fac=0.5, learning_rate=0.001, batch_size=256, num_workers=1, train_epochs=10, lradj='type3', patience=5, gpt_layers=3, is_gpt=1, e_layers=3, d_model=768, n_heads=4, d_ff=768, dropout=0.3, enc_in=1, c_out=1, patch_size=16, kernel_size=25, loss_func='mse', pretrain=1, freeze=1, model='TEMPO', stride=8, max_len=-1, hid_dim=16, tmax=20, itr=1, cos=1, equal=1, pool=False, no_stl_loss=False, stl_weight=0.001, config_path='./configs/multiple_datasets.yml', datasets='ILI', target_data='ILI', use_token=0, electri_multiplier=1, traffic_multiplier=1, embed='timeF')
['ILI']
ILI
dataset:  custom
676 104 25 1
train 549
676 104 25 1
676 104 25 1
676 104 25 1
201 104 25 1
val 74
201 104 25 1
201 104 25 1
201 104 25 1
ILI
dataset:  custom
676 104 25 1
train 549
676 104 25 1
676 104 25 1
676 104 25 1
297 104 25 1
test 170
297 104 25 1
676 104 25 1
trainable params: 154368 || all params: 60796416 || trainable%: 0.25
676 104 25 1
676 104 25 1
676 104 25 1
676 104 25 1
Epoch: 1 cost time: 0.8231899738311768
201 104 25 1
201 104 25 1
201 104 25 1
Epoch: 1, Steps: 2 | Train Loss: 1.3598389 Vali Loss: 0.2599086
lr = 0.0009938442
Validation loss decreased (inf --> 0.259909).  Saving model ...
676 104 25 1
676 104 25 1
676 104 25 1
676 104 25 1
Epoch: 2 cost time: 0.3357393741607666
201 104 25 1
201 104 25 1
201 104 25 1
Epoch: 2, Steps: 2 | Train Loss: 0.5833138 Vali Loss: 0.6814768
lr = 0.0009755285
EarlyStopping counter: 1 out of 5
676 104 25 1
676 104 25 1
676 104 25 1
676 104 25 1
Epoch: 3 cost time: 0.30784058570861816
201 104 25 1
201 104 25 1
201 104 25 1
Epoch: 3, Steps: 2 | Train Loss: 0.7575317 Vali Loss: 0.2188256
lr = 0.0009455038
Validation loss decreased (0.259909 --> 0.218826).  Saving model ...
676 104 25 1
676 104 25 1
676 104 25 1
676 104 25 1
Epoch: 4 cost time: 0.30919981002807617
201 104 25 1
201 104 25 1
201 104 25 1
Epoch: 4, Steps: 2 | Train Loss: 0.3508363 Vali Loss: 0.4141122
lr = 0.0009045095
EarlyStopping counter: 1 out of 5
676 104 25 1
676 104 25 1
676 104 25 1
676 104 25 1
Epoch: 5 cost time: 0.30830860137939453
201 104 25 1
201 104 25 1
201 104 25 1
Epoch: 5, Steps: 2 | Train Loss: 0.4558532 Vali Loss: 0.1508525
lr = 0.0008535549
Validation loss decreased (0.218826 --> 0.150853).  Saving model ...
676 104 25 1
676 104 25 1
676 104 25 1
676 104 25 1
Epoch: 6 cost time: 0.3271644115447998
201 104 25 1
201 104 25 1
201 104 25 1
Epoch: 6, Steps: 2 | Train Loss: 0.2124432 Vali Loss: 0.1588999
lr = 0.0007938947
EarlyStopping counter: 1 out of 5
676 104 25 1
676 104 25 1
676 104 25 1
676 104 25 1
Epoch: 7 cost time: 0.31768226623535156
201 104 25 1
201 104 25 1
201 104 25 1
Epoch: 7, Steps: 2 | Train Loss: 0.2645805 Vali Loss: 0.1579370
lr = 0.0007269980
EarlyStopping counter: 2 out of 5
676 104 25 1
676 104 25 1
676 104 25 1
676 104 25 1
Epoch: 8 cost time: 0.297468900680542
201 104 25 1
201 104 25 1
201 104 25 1
Epoch: 8, Steps: 2 | Train Loss: 0.2052237 Vali Loss: 0.1339380
lr = 0.0006545120
Validation loss decreased (0.150853 --> 0.133938).  Saving model ...
676 104 25 1
676 104 25 1
676 104 25 1
676 104 25 1
Epoch: 9 cost time: 0.31625866889953613
201 104 25 1
201 104 25 1
201 104 25 1
Epoch: 9, Steps: 2 | Train Loss: 0.1602651 Vali Loss: 0.1399054
lr = 0.0005782215
EarlyStopping counter: 1 out of 5
676 104 25 1
676 104 25 1
676 104 25 1
676 104 25 1
Epoch: 10 cost time: 0.3106248378753662
201 104 25 1
201 104 25 1
201 104 25 1
Epoch: 10, Steps: 2 | Train Loss: 0.1632560 Vali Loss: 0.1303236
lr = 0.0005000050
Validation loss decreased (0.133938 --> 0.130324).  Saving model ...
------------------------------------
297 104 25 1
297 104 25 1
Average MAE: 0.6279296875
Average MSE: 0.662109375
test on the ILI dataset: mse:0.662109375 mae:0.6279296875
mse_mean = 0.6621, mse_std = 0.0000
mae_mean = 0.6279, mae_std = 0.0000
logs/TEMPO/loar_revin_100_percent_1_prompt_equal_1/ettm2_pmt1_no_pool_TEMPO_3/test_104_36_lr0.001.log
Namespace(model_id='traffic_TEMPO_3_prompt_learn_104_36_100', checkpoints='./lora_revin_6domain_checkpoints_1/', task_name='long_term_forecast', prompt=1, num_nodes=1, seq_len=104, pred_len=36, label_len=18, decay_fac=0.5, learning_rate=0.001, batch_size=256, num_workers=1, train_epochs=10, lradj='type3', patience=5, gpt_layers=3, is_gpt=1, e_layers=3, d_model=768, n_heads=4, d_ff=768, dropout=0.3, enc_in=1, c_out=1, patch_size=16, kernel_size=25, loss_func='mse', pretrain=1, freeze=1, model='TEMPO', stride=8, max_len=-1, hid_dim=16, tmax=20, itr=1, cos=1, equal=1, pool=False, no_stl_loss=False, stl_weight=0.001, config_path='./configs/multiple_datasets.yml', datasets='ILI', target_data='ILI', use_token=0, electri_multiplier=1, traffic_multiplier=1, embed='timeF')
['ILI']
ILI
dataset:  custom
676 104 37 1
train 537
676 104 37 1
676 104 37 1
676 104 37 1
201 104 37 1
val 62
201 104 37 1
201 104 37 1
201 104 37 1
ILI
dataset:  custom
676 104 37 1
train 537
676 104 37 1
676 104 37 1
676 104 37 1
297 104 37 1
test 158
297 104 37 1
676 104 37 1
trainable params: 154368 || all params: 60796416 || trainable%: 0.25
676 104 37 1
676 104 37 1
676 104 37 1
676 104 37 1
Epoch: 1 cost time: 0.7876248359680176
201 104 37 1
201 104 37 1
201 104 37 1
Epoch: 1, Steps: 2 | Train Loss: 1.5198698 Vali Loss: 0.3242537
lr = 0.0009938442
Validation loss decreased (inf --> 0.324254).  Saving model ...
676 104 37 1
676 104 37 1
676 104 37 1
676 104 37 1
Epoch: 2 cost time: 0.2909209728240967
201 104 37 1
201 104 37 1
201 104 37 1
Epoch: 2, Steps: 2 | Train Loss: 0.5391421 Vali Loss: 0.6081134
lr = 0.0009755285
EarlyStopping counter: 1 out of 5
676 104 37 1
676 104 37 1
676 104 37 1
676 104 37 1
Epoch: 3 cost time: 0.28130388259887695
201 104 37 1
201 104 37 1
201 104 37 1
Epoch: 3, Steps: 2 | Train Loss: 0.7437213 Vali Loss: 0.1968271
lr = 0.0009455038
Validation loss decreased (0.324254 --> 0.196827).  Saving model ...
676 104 37 1
676 104 37 1
676 104 37 1
676 104 37 1
Epoch: 4 cost time: 0.2924666404724121
201 104 37 1
201 104 37 1
201 104 37 1
Epoch: 4, Steps: 2 | Train Loss: 0.3404730 Vali Loss: 0.3758103
lr = 0.0009045095
EarlyStopping counter: 1 out of 5
676 104 37 1
676 104 37 1
676 104 37 1
676 104 37 1
Epoch: 5 cost time: 0.29549646377563477
201 104 37 1
201 104 37 1
201 104 37 1
Epoch: 5, Steps: 2 | Train Loss: 0.4711888 Vali Loss: 0.1405540
lr = 0.0008535549
Validation loss decreased (0.196827 --> 0.140554).  Saving model ...
676 104 37 1
676 104 37 1
676 104 37 1
676 104 37 1
Epoch: 6 cost time: 0.29158949851989746
201 104 37 1
201 104 37 1
201 104 37 1
Epoch: 6, Steps: 2 | Train Loss: 0.2147938 Vali Loss: 0.1547333
lr = 0.0007938947
EarlyStopping counter: 1 out of 5
676 104 37 1
676 104 37 1
676 104 37 1
676 104 37 1
Epoch: 7 cost time: 0.3017251491546631
201 104 37 1
201 104 37 1
201 104 37 1
Epoch: 7, Steps: 2 | Train Loss: 0.2797012 Vali Loss: 0.1643688
lr = 0.0007269980
EarlyStopping counter: 2 out of 5
676 104 37 1
676 104 37 1
676 104 37 1
676 104 37 1
Epoch: 8 cost time: 0.2887136936187744
201 104 37 1
201 104 37 1
201 104 37 1
Epoch: 8, Steps: 2 | Train Loss: 0.2166884 Vali Loss: 0.1457936
lr = 0.0006545120
EarlyStopping counter: 3 out of 5
676 104 37 1
676 104 37 1
676 104 37 1
676 104 37 1
Epoch: 9 cost time: 0.29351806640625
201 104 37 1
201 104 37 1
201 104 37 1
Epoch: 9, Steps: 2 | Train Loss: 0.1753616 Vali Loss: 0.1743281
lr = 0.0005782215
EarlyStopping counter: 4 out of 5
676 104 37 1
676 104 37 1
676 104 37 1
676 104 37 1
Epoch: 10 cost time: 0.3062150478363037
201 104 37 1
201 104 37 1
201 104 37 1
Epoch: 10, Steps: 2 | Train Loss: 0.1929132 Vali Loss: 0.1479443
lr = 0.0005000050
EarlyStopping counter: 5 out of 5
Early stopping
------------------------------------
297 104 37 1
297 104 37 1
Average MAE: 0.79833984375
Average MSE: 0.91748046875
test on the ILI dataset: mse:0.91748046875 mae:0.79833984375
mse_mean = 0.9175, mse_std = 0.0000
mae_mean = 0.7983, mae_std = 0.0000
logs/TEMPO/loar_revin_100_percent_1_prompt_equal_1/ettm2_pmt1_no_pool_TEMPO_3/test_104_48_lr0.001.log
Namespace(model_id='traffic_TEMPO_3_prompt_learn_104_48_100', checkpoints='./lora_revin_6domain_checkpoints_1/', task_name='long_term_forecast', prompt=1, num_nodes=1, seq_len=104, pred_len=48, label_len=18, decay_fac=0.5, learning_rate=0.001, batch_size=256, num_workers=1, train_epochs=10, lradj='type3', patience=5, gpt_layers=3, is_gpt=1, e_layers=3, d_model=768, n_heads=4, d_ff=768, dropout=0.3, enc_in=1, c_out=1, patch_size=16, kernel_size=25, loss_func='mse', pretrain=1, freeze=1, model='TEMPO', stride=8, max_len=-1, hid_dim=16, tmax=20, itr=1, cos=1, equal=1, pool=False, no_stl_loss=False, stl_weight=0.001, config_path='./configs/multiple_datasets.yml', datasets='ILI', target_data='ILI', use_token=0, electri_multiplier=1, traffic_multiplier=1, embed='timeF')
['ILI']
ILI
dataset:  custom
676 104 49 1
train 525
676 104 49 1
676 104 49 1
676 104 49 1
201 104 49 1
val 50
201 104 49 1
201 104 49 1
201 104 49 1
ILI
dataset:  custom
676 104 49 1
train 525
676 104 49 1
676 104 49 1
676 104 49 1
297 104 49 1
test 146
297 104 49 1
676 104 49 1
trainable params: 154368 || all params: 60796416 || trainable%: 0.25
676 104 49 1
676 104 49 1
676 104 49 1
676 104 49 1
Epoch: 1 cost time: 0.821749210357666
201 104 49 1
201 104 49 1
201 104 49 1
Epoch: 1, Steps: 2 | Train Loss: 1.4206332 Vali Loss: 0.3033646
lr = 0.0009938442
Validation loss decreased (inf --> 0.303365).  Saving model ...
676 104 49 1
676 104 49 1
676 104 49 1
676 104 49 1
Epoch: 2 cost time: 0.316927433013916
201 104 49 1
201 104 49 1
201 104 49 1
Epoch: 2, Steps: 2 | Train Loss: 0.5826780 Vali Loss: 0.5172760
lr = 0.0009755285
EarlyStopping counter: 1 out of 5
676 104 49 1
676 104 49 1
676 104 49 1
676 104 49 1
Epoch: 3 cost time: 0.3123295307159424
201 104 49 1
201 104 49 1
201 104 49 1
Epoch: 3, Steps: 2 | Train Loss: 0.6991035 Vali Loss: 0.1941247
lr = 0.0009455038
Validation loss decreased (0.303365 --> 0.194125).  Saving model ...
676 104 49 1
676 104 49 1
676 104 49 1
676 104 49 1
Epoch: 4 cost time: 0.33121275901794434
201 104 49 1
201 104 49 1
201 104 49 1
Epoch: 4, Steps: 2 | Train Loss: 0.3532481 Vali Loss: 0.4760518
lr = 0.0009045095
EarlyStopping counter: 1 out of 5
676 104 49 1
676 104 49 1
676 104 49 1
676 104 49 1
Epoch: 5 cost time: 0.31655216217041016
201 104 49 1
201 104 49 1
201 104 49 1
Epoch: 5, Steps: 2 | Train Loss: 0.4350070 Vali Loss: 0.1811620
lr = 0.0008535549
Validation loss decreased (0.194125 --> 0.181162).  Saving model ...
676 104 49 1
676 104 49 1
676 104 49 1
676 104 49 1
Epoch: 6 cost time: 0.33233022689819336
201 104 49 1
201 104 49 1
201 104 49 1
Epoch: 6, Steps: 2 | Train Loss: 0.2358137 Vali Loss: 0.1703289
lr = 0.0007938947
Validation loss decreased (0.181162 --> 0.170329).  Saving model ...
676 104 49 1
676 104 49 1
676 104 49 1
676 104 49 1
Epoch: 7 cost time: 0.33110761642456055
201 104 49 1
201 104 49 1
201 104 49 1
Epoch: 7, Steps: 2 | Train Loss: 0.2969189 Vali Loss: 0.1247062
lr = 0.0007269980
Validation loss decreased (0.170329 --> 0.124706).  Saving model ...
676 104 49 1
676 104 49 1
676 104 49 1
676 104 49 1
Epoch: 8 cost time: 0.3120307922363281
201 104 49 1
201 104 49 1
201 104 49 1
Epoch: 8, Steps: 2 | Train Loss: 0.1992166 Vali Loss: 0.1546696
lr = 0.0006545120
EarlyStopping counter: 1 out of 5
676 104 49 1
676 104 49 1
676 104 49 1
676 104 49 1
Epoch: 9 cost time: 0.3146672248840332
201 104 49 1
201 104 49 1
201 104 49 1
Epoch: 9, Steps: 2 | Train Loss: 0.1857549 Vali Loss: 0.1892365
lr = 0.0005782215
EarlyStopping counter: 2 out of 5
676 104 49 1
676 104 49 1
676 104 49 1
676 104 49 1
Epoch: 10 cost time: 0.311633825302124
201 104 49 1
201 104 49 1
201 104 49 1
Epoch: 10, Steps: 2 | Train Loss: 0.1904577 Vali Loss: 0.1425817
lr = 0.0005000050
EarlyStopping counter: 3 out of 5
------------------------------------
297 104 49 1
297 104 49 1
Average MAE: 1.017578125
Average MSE: 1.3251953125
test on the ILI dataset: mse:1.3251953125 mae:1.017578125
mse_mean = 1.3252, mse_std = 0.0000
mae_mean = 1.0176, mae_std = 0.0000
logs/TEMPO/loar_revin_100_percent_1_prompt_equal_1/ettm2_pmt1_no_pool_TEMPO_3/test_104_60_lr0.001.log
Namespace(model_id='traffic_TEMPO_3_prompt_learn_104_60_100', checkpoints='./lora_revin_6domain_checkpoints_1/', task_name='long_term_forecast', prompt=1, num_nodes=1, seq_len=104, pred_len=60, label_len=18, decay_fac=0.5, learning_rate=0.001, batch_size=256, num_workers=1, train_epochs=10, lradj='type3', patience=5, gpt_layers=3, is_gpt=1, e_layers=3, d_model=768, n_heads=4, d_ff=768, dropout=0.3, enc_in=1, c_out=1, patch_size=16, kernel_size=25, loss_func='mse', pretrain=1, freeze=1, model='TEMPO', stride=8, max_len=-1, hid_dim=16, tmax=20, itr=1, cos=1, equal=1, pool=False, no_stl_loss=False, stl_weight=0.001, config_path='./configs/multiple_datasets.yml', datasets='ILI', target_data='ILI', use_token=0, electri_multiplier=1, traffic_multiplier=1, embed='timeF')
['ILI']
ILI
dataset:  custom
676 104 61 1
train 513
676 104 61 1
676 104 61 1
676 104 61 1
201 104 61 1
val 38
201 104 61 1
201 104 61 1
201 104 61 1
ILI
dataset:  custom
676 104 61 1
train 513
676 104 61 1
676 104 61 1
676 104 61 1
297 104 61 1
test 134
297 104 61 1
676 104 61 1
trainable params: 154368 || all params: 60796416 || trainable%: 0.25
676 104 61 1
676 104 61 1
676 104 61 1
676 104 61 1
Epoch: 1 cost time: 0.8545949459075928
201 104 61 1
201 104 61 1
201 104 61 1
Epoch: 1, Steps: 2 | Train Loss: 1.3440061 Vali Loss: 0.3120385
lr = 0.0009938442
Validation loss decreased (inf --> 0.312038).  Saving model ...
676 104 61 1
676 104 61 1
676 104 61 1
676 104 61 1
Epoch: 2 cost time: 0.3091411590576172
201 104 61 1
201 104 61 1
201 104 61 1
Epoch: 2, Steps: 2 | Train Loss: 0.5661476 Vali Loss: 0.4890466
lr = 0.0009755285
EarlyStopping counter: 1 out of 5
676 104 61 1
676 104 61 1
676 104 61 1
676 104 61 1
Epoch: 3 cost time: 0.3302159309387207
201 104 61 1
201 104 61 1
201 104 61 1
Epoch: 3, Steps: 2 | Train Loss: 0.6515670 Vali Loss: 0.2285182
lr = 0.0009455038
Validation loss decreased (0.312038 --> 0.228518).  Saving model ...
676 104 61 1
676 104 61 1
676 104 61 1
676 104 61 1
Epoch: 4 cost time: 0.32036590576171875
201 104 61 1
201 104 61 1
201 104 61 1
Epoch: 4, Steps: 2 | Train Loss: 0.3714422 Vali Loss: 0.4547912
lr = 0.0009045095
EarlyStopping counter: 1 out of 5
676 104 61 1
676 104 61 1
676 104 61 1
676 104 61 1
Epoch: 5 cost time: 0.32271242141723633
201 104 61 1
201 104 61 1
201 104 61 1
Epoch: 5, Steps: 2 | Train Loss: 0.4296759 Vali Loss: 0.1493292
lr = 0.0008535549
Validation loss decreased (0.228518 --> 0.149329).  Saving model ...
676 104 61 1
676 104 61 1
676 104 61 1
676 104 61 1
Epoch: 6 cost time: 0.301922082901001
201 104 61 1
201 104 61 1
201 104 61 1
Epoch: 6, Steps: 2 | Train Loss: 0.2425589 Vali Loss: 0.1756744
lr = 0.0007938947
EarlyStopping counter: 1 out of 5
676 104 61 1
676 104 61 1
676 104 61 1
676 104 61 1
Epoch: 7 cost time: 0.30295276641845703
201 104 61 1
201 104 61 1
201 104 61 1
Epoch: 7, Steps: 2 | Train Loss: 0.3020426 Vali Loss: 0.1643954
lr = 0.0007269980
EarlyStopping counter: 2 out of 5
676 104 61 1
676 104 61 1
676 104 61 1
676 104 61 1
Epoch: 8 cost time: 0.30147314071655273
201 104 61 1
201 104 61 1
201 104 61 1
Epoch: 8, Steps: 2 | Train Loss: 0.2187989 Vali Loss: 0.1823764
lr = 0.0006545120
EarlyStopping counter: 3 out of 5
676 104 61 1
676 104 61 1
676 104 61 1
676 104 61 1
Epoch: 9 cost time: 0.30756425857543945
201 104 61 1
201 104 61 1
201 104 61 1
Epoch: 9, Steps: 2 | Train Loss: 0.1917977 Vali Loss: 0.1965607
lr = 0.0005782215
EarlyStopping counter: 4 out of 5
676 104 61 1
676 104 61 1
676 104 61 1
676 104 61 1
Epoch: 10 cost time: 0.3082141876220703
201 104 61 1
201 104 61 1
201 104 61 1
Epoch: 10, Steps: 2 | Train Loss: 0.2005241 Vali Loss: 0.1352694
lr = 0.0005000050
Validation loss decreased (0.149329 --> 0.135269).  Saving model ...
------------------------------------
297 104 61 1
297 104 61 1
Average MAE: 0.80029296875
Average MSE: 0.90966796875
test on the ILI dataset: mse:0.90966796875 mae:0.80029296875
mse_mean = 0.9097, mse_std = 0.0000
mae_mean = 0.8003, mae_std = 0.0000
